{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ff2a1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import gspread\n",
    "from google.oauth2.service_account import Credentials\n",
    "from gspread_dataframe import set_with_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "844a628a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        page_location  scrolls  words\n",
      "0   https://news.wm.edu/2025/04/08/william-mary-co...     5765    724\n",
      "1   https://news.wm.edu/announcements/notice-to-th...     5131    341\n",
      "2   https://news.wm.edu/2025/04/08/william-mary-co...     4428    724\n",
      "3                                https://news.wm.edu/     4026    485\n",
      "4   https://news.wm.edu/2025/04/09/roll-out-the-gr...     2611    732\n",
      "..                                                ...      ...    ...\n",
      "94  https://news.wm.edu/2025/04/18/william-marys-b...      179    902\n",
      "95  https://news.wm.edu/2025/04/16/virginias-exper...      178    756\n",
      "96  https://news.wm.edu/2025/03/31/ncis-leader-alu...      175    839\n",
      "97  https://news.wm.edu/announcements/notice-to-th...      169    289\n",
      "98  https://news.wm.edu/2025/04/21/sean-galloway-s...      163    751\n",
      "\n",
      "[99 rows x 3 columns]\n",
      "Processing complete. Results written to 'output' sheet.\n"
     ]
    }
   ],
   "source": [
    "def get_english_dictionary():\n",
    "    \"\"\"Retrieve English dictionary from GitHub.\"\"\"\n",
    "    dict_url = \"https://github.com/dwyl/english-words/raw/master/words_alpha.txt\"\n",
    "    response = requests.get(dict_url)\n",
    "    # Strip both \\n and \\r characters\n",
    "    words = set(word.strip() for word in response.text.lower().strip().split('\\n'))\n",
    "    return words\n",
    "\n",
    "def return_words(web_page):\n",
    "    \"\"\"Count English words on a web page.\"\"\"\n",
    "    try:\n",
    "        # Fetch and parse the web page\n",
    "        response = requests.get(web_page)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Extract text and clean it\n",
    "        text = soup.get_text()\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[\",:.\\\\n]', '', text)\n",
    "        \n",
    "        # Split into words and count those in the dictionary\n",
    "        page_words = text.split()\n",
    "\n",
    "        english_count = sum(1 for word in page_words if word in english_dictionary)\n",
    "        return english_count\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to process URLs and update Google Sheet.\"\"\"\n",
    "    # Set up Google Sheets authentication\n",
    "    # You'll need to create a service account and download credentials.json\n",
    "    scopes = [\n",
    "        'https://www.googleapis.com/auth/spreadsheets',\n",
    "        'https://www.googleapis.com/auth/drive'\n",
    "    ]\n",
    "    \n",
    "    credentials = Credentials.from_service_account_file(\n",
    "        'gtm-543z2mjn-yjqzn-f18077312981.json',\n",
    "        scopes=scopes\n",
    "    )\n",
    "    \n",
    "    gc = gspread.authorize(credentials)\n",
    "    \n",
    "    # Open the sheet\n",
    "    sheet_url = 'https://docs.google.com/spreadsheets/d/1z8aZvcrRkiHb9hvb29gD-q8dUXsDDQXBSKxhGKXUR5Q/edit?usp=sharing'\n",
    "    spreadsheet = gc.open_by_url(sheet_url)\n",
    "    \n",
    "    # Read data from the sheet\n",
    "    worksheet = spreadsheet.sheet1  # Assuming URLs are in the first sheet\n",
    "    page_data = pd.DataFrame(worksheet.get_all_records())\n",
    "    \n",
    "    # Get English dictionary\n",
    "    global english_dictionary\n",
    "    english_dictionary = get_english_dictionary()\n",
    "        \n",
    "    # Process each URL and count words\n",
    "    page_data['words'] = page_data['page_location'].apply(return_words)\n",
    "    \n",
    "    print(page_data)\n",
    "    \n",
    "    # Write results to a new sheet\n",
    "    try:\n",
    "        output_sheet = spreadsheet.worksheet('output')\n",
    "    except:\n",
    "        output_sheet = spreadsheet.add_worksheet(title='output', rows=100, cols=20)\n",
    "    \n",
    "    set_with_dataframe(output_sheet, page_data)\n",
    "    print(\"Processing complete. Results written to 'output' sheet.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee4b846",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
